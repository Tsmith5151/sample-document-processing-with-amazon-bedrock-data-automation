{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57822f24-f213-4efa-980d-da399ee03a4a",
   "metadata": {},
   "source": [
    "# Automating insurance claim processing using BDA and Bedrock Agents\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Generative AI agents are a powerful tool for large enterprises, as they can enhance operational efficiency, customer service, and decision-making while reducing costs and enabling innovation. These agents excel at automating a wide range of routine and repetitive tasks, and can orchestrate complex, multi-step workflows.\n",
    "\n",
    "Amazon Bedrock Agents and Amazon Bedrock Knowledge Bases enable the creation of specialized agents that can automate tasks associated with the enterprise workflows, efficiently scale and improve customer service, and enhance decision support through improved knowledge management.\n",
    "\n",
    "Integrating Amazon Bedrock Data Automation (BDA) with the Bedrock Agents and Knowledge Bases provides a comprehensive, automated, and scalable solution for efficiently processing and extracting insights from diverse data sources for your organization's use cases.\n",
    "\n",
    "In this notebook, we go through an end-to-end solution for one such use case, Insurance claims management. Insurance companies deal with a high volume of claims, which can be time-consuming and prone to errors when processed manually. By leveraging capabilities provided by Amazon Bedrock including Bedrock Data Automation and Bedrock Agents, We will explore a generative AI-powered solution that streamlines the claim process, improves efficiency, and enhances customer experience. \n",
    "\n",
    "There is an associated deployable solution in this [Github repository](https://github.com/aws-solutions-library-samples/guidance-for-multimodal-data-processing-using-amazon-bedrock-data-automation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a8c4d-3b99-4130-85e6-094c2d391c8b",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f3f1e9-684e-428d-9598-a018da023dfc",
   "metadata": {},
   "source": [
    "----\n",
    "The architecture for the solution is shown below. The process begins with a Medical Claim Form (CMS 1500) received from a medical provider -\n",
    "\n",
    "### Claim Review Process\n",
    "\n",
    "- **Step 1:** Medical provider submits the claim, which is stored in an S3 bucket.\n",
    "\n",
    "- **Step 2:** An S3 Object Created event is matched by a configured EventBridge Rule.\n",
    "- **Step 3:** EventBridge rule triggers a AWS Lambda function.\n",
    "- **Step 4:** The Lambda function in turn calls the `InvokeDataAutomationAsync` job in BDA along with a custom blueprint.\n",
    "- **Step 5:** BDA uses the provided custom blueprint for the CMS 1500 form to extract the content of the -claim.BDA stores extracted claims data in the S3 bucket specified in the API call.\n",
    "- **Step 6:** BDA sends a Job completion event to EventBridge that include the job status and the S3 uri of the response and metadata.\n",
    "- **Step 7:** EventBridge rule triggers an AWS Lambda function\n",
    "- **Step 8:** The Lambda function uses the BDA job response and metadata to fetch extracted claim form data.\n",
    "- **Step 9:** The Lambda function then invokes the pre-configured Bedrock Agent to process the claim\n",
    "- **Step 10:** Bedrock Agent uses configured agent actions (fulfilled by Lambda function) to perform tasks required during claim verification process.\n",
    "- **Step 11:** Bedrock Agent uses agent action, implemented using Lambda function, to query member and patient information stored in Aurora Postgres in order to complete claim verification. Agent also uses the agent action  to stores verified claim details in the database.\n",
    "- **Step 12:** Bedrock Agent query Bedrock knowledge Base to gathers coverage details on the treatments, services and supplies provided in the claims form\n",
    "- **Step 13:** Bedrock Agent create a final report to detail the validation process and stores the report in S3\n",
    "\n",
    "\n",
    "### Claim Policy Knowledge Ingestion Process\n",
    "The Knowledge Base is used for Retrieval Augmented Generation (RAG), a technique that uses information from data sources to improve the relevancy and accuracy of generated responses. In this example, the knowledge base converts claim policy documents in pdf format into vector embeddings and stored in a vector store (Amazon Opensearch serverless vector index). This process of converting the data into vector embeddings is called ingestion. The Ingestion process is carried out to make the knowledge base ready to be queried by the agent (or humans). \n",
    "\n",
    "[More details on the Ingestion process](https://docs.aws.amazon.com/bedrock/latest/userguide/kb-how-data.html)\n",
    "\n",
    "- **Step 1:** Medical provider uploads claim policy document to S3 bucket.\n",
    "  \n",
    "- **Step 2:** An S3 Object Created event is matched by a configured EventBridge Rule.\n",
    "- **Step 3:** EventBridge rule triggers a AWS Lambda function.\n",
    "- **Step 4:** Lambda function in turn invokes `StartIngestionJob` api to trigger a Knowledge Base datasource sync job\n",
    "- **Step 5:** The datasource sync job incrementally converts the raw claim policy documents in the S3 bucket into vector embeddings, based on the vector embeddings model and configurations specified \n",
    "- **Step 6:** The vector embeddings are store in the configured vector store (opensearch serverless in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ab202-3461-4833-8d76-87a929baa4c7",
   "metadata": {},
   "source": [
    "![Claims Review Architecture](data/images/Medical_Claims_Processing_Architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd55a09-150b-49b8-bd67-62beb6bbe99a",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Before starting this notebook, ensure you have:\n",
    "\n",
    "1. An AWS account with access to Amazon Bedrock\n",
    "2. Necessary IAM permissions to create and manage Bedrock resources\n",
    "3. <a id=\"stack\">Install the Insurance Claims Review stack using AWS CloudFormation with this</a> [template](https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/c64e3606-ab68-4521-81ea-b2eb36c993b9/templates/bda-idp-workshop.yaml)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a260a0b-91f4-4473-b3e6-64d8b0c2a094",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In the following sections we would run through the process to setup the AWS resources required to run the end-to-end flow for claim processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8eab38-b939-4a2d-bc23-0a9a3de6afca",
   "metadata": {},
   "source": [
    "### Install Required Libraries\n",
    "First, let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc60997-9c3b-4747-be4a-dcd72d7b7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"boto3>=1.37.6\" itables==2.2.4 PyPDF2==3.0.1 --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042c455-9b3f-4a17-9814-8d40961fc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edcd0cb-b160-45b0-b818-25ec9e66d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from utils import helper_functions\n",
    "from utils import bedrock_utils\n",
    "from utils import display_functions\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from IPython.display import JSON, display, IFrame, Markdown\n",
    "import os\n",
    "import shutil\n",
    "from urllib.parse import urlparse\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "# Set up AWS credentials (make sure you have the appropriate permissions)\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "s3_client = session.client('s3')\n",
    "bedrock = session.client('bedrock')\n",
    "bedrock_agent = session.client('bedrock-agent')\n",
    "bedrock_agent_runtime = session.client('bedrock-agent-runtime')\n",
    "bda_client = boto3.client('bedrock-data-automation')\n",
    "bda_runtime_client = boto3.client('bedrock-data-automation-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1a3fe-48ec-4705-983d-f0c7b3355f55",
   "metadata": {},
   "source": [
    "### Set BDA Input / Output Locations in S3\n",
    "BDA `InvokeDataAutomationAsync` API uses S3 for receiving input files to process and to store the output results. We set a S3 location each for input files and output results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09921884-0c5a-4aa7-b21c-36a775d29db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bda_workshop_s3_location = f's3://{default_bucket}/bda-workshop'\n",
    "bda_s3_input_location = f'{bda_workshop_s3_location}/input'\n",
    "bda_s3_output_location = f'{bda_workshop_s3_location}/output'\n",
    "agent_review_s3_input_location = f'{bda_workshop_s3_location}/agent_input'\n",
    "eoc_document_s3_location = f'{bda_workshop_s3_location}/eoc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be97fcb-e182-490d-9349-076c909340a0",
   "metadata": {},
   "source": [
    "## Creating and Configuring Bedrock Knowledge Base\n",
    "Amazon Bedrock Knowledge Bases help you take advantage of Retrieval Augmented Generation (RAG), a popular technique that involves drawing information from a data store to augment the responses generated by Large Language Models (LLMs). When you set up a knowledge base with your data source, your application can query the knowledge base to return information to answer the query either with direct quotations from sources or with natural responses generated from the query results.\n",
    "\n",
    "In our solution, we use Amazon Bedrock Knowledge Base for enriching our claim processing with coverage and policy information from the evidence of coverage documents that we ingest into the Knowledge Base through our data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70632b-52b8-4ef9-9966-a1fa556f74be",
   "metadata": {},
   "source": [
    "### Fetch attributes for pre-configured resources\n",
    "Many of AWS resources that are used in our solution would be pre-created so that we can focus on the BDA and Bedrock Agents part of the solution. See [Prerequisites](#stack)\n",
    "\n",
    "Here we extract some of the resource attributes from our pre-created stack. that our Bedrock Knowlege Base resources would need to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d604a005-6c4a-4b06-b875-6c44afb4548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_resource_attributes = helper_functions.get_stack_outputs()\n",
    "embedding_model_arn = f'arn:aws:bedrock:{region_name}::foundation-model/amazon.titan-embed-text-v2:0'\n",
    "kb_role_arn = stack_resource_attributes['KBServiceRole']\n",
    "vector_store_index_name = stack_resource_attributes['ClaimsVectorStoreIndexName']\n",
    "vector_store_collection_arn = stack_resource_attributes['ClaimsVectorStoreCollectionArn']\n",
    "vector_store_collection_name = stack_resource_attributes['ClaimsVectorStoreCollectionName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69d5b8-2b5e-43d1-b9c4-e240aa21017c",
   "metadata": {},
   "source": [
    "### Create the Knowledge Base\n",
    "A Knowledge Base for evidence of coverage (EoC) documents in insurance claim processing serves as a centralized repository that stores and organizes policy documentation, coverage details, and related insurance terms. It enables the automated system to quickly access, interpret, and validate coverage information when processing claims by comparing incoming claims against stored policy rules and conditions. This streamlines verification of coverage eligibility, policy limits, exclusions, and specific terms, reducing manual lookup time and potential human errors while ensuring consistent and accurate claim decisions based on the documented coverage parameters.\n",
    "\n",
    "Here we create a Bedrock Knowledge Base with an OpenSearch Serverless Vector store (pre-created) and an S3 datasource where we upload our EoC documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390bc04-18f6-4151-a1e3-278e5d602f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_id, status = bedrock_utils.create_knowledge_base(\n",
    "    bedrock_agent,\n",
    "    kb_name=f'claims-eoc-kb-{account_id}',\n",
    "    kb_description='Knowledge Base for Insurance Evidence of Coverage documents that details the plan\\'s costs and benefits',\n",
    "    embedding_model_arn=embedding_model_arn,\n",
    "    kb_role_arn=kb_role_arn,\n",
    "    vector_store_collection_arn=vector_store_collection_arn,\n",
    "    vector_store_index_name=vector_store_index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd9802-885c-47a6-81f7-32b3749703fb",
   "metadata": {},
   "source": [
    "### Connecting a data source to the knowledge base\n",
    "After finishing the configurations for our knowledge base, we connect a supported data source to the knowledge base. Data sources contain information returned when querying a Knowledge Base. For our solution, we connect to a custom data source. Using a custom data source provides use the ability to use the `KnowledgeBaseDocuments` API operations to directly ingest or delete documents without the need to sync changes. For details see [Connect your knowledge base to a custom data source](https://docs.aws.amazon.com/bedrock/latest/userguide/custom-data-source-connector.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef781c-329b-4872-b813-9555ca94a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_id, status = bedrock_utils.create_data_source(bedrock_agent, knowledge_base_id, datasource_name=f'claims-eoc-datasource-{account_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a279c36-0d90-4b5e-8a61-b488823ff1d4",
   "metadata": {},
   "source": [
    "### Ingesting Documents into Knowledge Base\n",
    "To demonstrate the concept of using Knowledge bases to automatically enrich claim processing lifecycle with coverage information, We use a set of machine-generated EoC documents and ingest them directly to our Knowledge Base we created earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8428c1-779b-45e7-b972-c60439217910",
   "metadata": {},
   "source": [
    "#### Upload EoC Documents to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5086f24-c74b-4a68-84d1-8bcc8e639c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_urls = [\n",
    "    'https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/c64e3606-ab68-4521-81ea-b2eb36c993b9/samples/Evidence_of_Coverage_-_AnyHealth_Premium.pdf',\n",
    "    'https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/c64e3606-ab68-4521-81ea-b2eb36c993b9/samples/Evidence_of_Coverage_-_AnyHealth_Standard.pdf',\n",
    "    'https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/c64e3606-ab68-4521-81ea-b2eb36c993b9/samples/Evidence_of_Coverage_-_AnyHealth_Plus.pdf']\n",
    "\n",
    "local_documents_path = 'data/documents'\n",
    "\n",
    "eoc_documents_path = os.path.join(local_documents_path, 'eoc')\n",
    "# Create full path of directories\n",
    "os.makedirs(eoc_documents_path, exist_ok=True)\n",
    "for document_url in document_urls:\n",
    "    parsed = urlparse(document_url)\n",
    "    local_file_name = parsed.path.split('/')[-1]\n",
    "    local_file_path = os.path.join(eoc_documents_path, local_file_name)\n",
    "    !curl {document_url} --output {local_file_path}\n",
    "\n",
    "!aws s3 cp {eoc_documents_path} {eoc_document_s3_location} --recursive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f8f39-1d90-4ac9-ac3e-3b757345a987",
   "metadata": {},
   "source": [
    "#### Ingest EoC Documents directly into our Knowledge Base\n",
    "\n",
    "After setting up our custom data source, we can add our EoC documents into it and directly ingest them into the knowledge base. Unlike other data sources, we don't need to sync a custom data source. This feature allows us to modify our data source and sync the changes in one step. For details see [Ingest changes directly into a knowledge base](https://docs.aws.amazon.com/bedrock/latest/userguide/kb-direct-ingestion.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41642d-1726-466f-b142-44a9aa6dfb36",
   "metadata": {},
   "source": [
    "When ingesting documents directly into Knowledge Base, we need to provide the `DocumentContent` to the `IngestKnowledgeBaseDocuments` API, that contains information about a document to ingest into a knowledge base and any metadata to associate with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f219eef0-a533-4ca6-86eb-6c2727e18f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [{\n",
    "    'plan_name':'AnyHealth_Standard',\n",
    "    'document_id': 'Evidence_of_Coverage_-_AnyHealth_Standard.pdf',\n",
    "    'document_uri': f'{eoc_document_s3_location}/Evidence_of_Coverage_-_AnyHealth_Standard.pdf'\n",
    "},\n",
    "{\n",
    "    'plan_name':'AnyHealth_Premium',\n",
    "    'document_id': 'Evidence_of_Coverage_-_AnyHealth_Premium.pdf',\n",
    "    'document_uri': f'{eoc_document_s3_location}/Evidence_of_Coverage_-_AnyHealth_Premium.pdf'\n",
    "},\n",
    "{\n",
    "    'plan_name':'AnyHealth_Plus',\n",
    "    'document_id': 'Evidence_of_Coverage_-_AnyHealth_Plus.pdf',\n",
    "    'document_uri': f'{eoc_document_s3_location}/Evidence_of_Coverage_-_AnyHealth_Plus.pdf'\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15986203-8504-4eb0-851f-b0c650397a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bedrock_utils.ingest_and_wait(bedrock_agent, data_source_id, knowledge_base_id, documents)\n",
    "results_view = [(item['identifier']['custom']['id'], item['status']) for item in results]\n",
    "display(pd.DataFrame(results_view).style.hide(axis='index').hide(axis='columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e346a5-03ab-4c57-a5c2-b7eb1daa7b14",
   "metadata": {},
   "source": [
    "## Creating an Agent\n",
    "Amazon Bedrock Agents offers you the ability to build and configure autonomous agents your applications. AI Agents can interact with users, make decisions, and take actions. These agents combine foundation models with organizational data, APIs, and knowledge bases to handle complex tasks and conversations, simplifying the development of generative AI applications by providing a pre-built framework for integrating various AI capabilities and data sources.\n",
    "\n",
    "To create an agent with Amazon Bedrock, you set up the following components:\n",
    "\n",
    "<table width=\"80%\">\n",
    "    <tr>\n",
    "        <th width=\"30%\"  align=\"left\" style=\"background-color: #999693\">Configuration</th>\n",
    "        <th width=\"70%\" align=\"left\" style=\"background-color: #999693\">Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Agent resource role</b></td>\n",
    "        <td>A service role with permissions to call API operations on the agent</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Foundation Model</b></td>\n",
    "        <td>An FM for the agent to invoke to perform orchestration</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Instructions</b></td>\n",
    "        <td>You write instructions that describe what the agent is designed to do. With advanced prompts, you can further customize instructions for the agent at every step of orchestration and include Lambda functions to parse each step's output</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Action Group</b></td>\n",
    "        <td>Defines actions that the agent can help end users perform. Each action group includes the parameters that the agent must provide when invoking the action.<br><br>\n",
    "        See <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/agents-action-create.html\">Use action groups to define actions for your agent</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Knowledge Base</b></td>\n",
    "        <td>Provides a repository of information that the agent can query to answer customer queries and improve its generated responses\n",
    "            <br><br><a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/agents-kb-add.html\">Augment response generation for your agent with knowledge base</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "For our solution, we create an agent that helps customers process insurance claims. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f499990-e239-4338-81fa-e9570a946a1e",
   "metadata": {},
   "source": [
    "### Fetch attributes for pre-configured resources\n",
    "Many of AWS resources that are used in our solution would be pre-created so that we can focus on the BDA and Bedrock Agents part of the solution. See [Prerequisites](#stack)\n",
    "\n",
    "Here we extract some of the resource attributes from our pre-created stack that the Bedrock Agent resources would need to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68d899-e12e-4f5e-a8fd-19a3cf89b7a8",
   "metadata": {},
   "source": [
    "### Choosing a foundation model\n",
    "You choose a foundation model (FM) that the agent invokes to interpret user input and subsequent prompts in its orchestration process. The agent also invokes the FM to generate responses and follow-up steps in its process.\n",
    "\n",
    "**When choosing a model please follow the model provider acceptable end user policy**.\n",
    "\n",
    "<details>\n",
    "  <summary>More Details </summary>\n",
    "\n",
    "        \n",
    "- [Model support by feature](https://docs.aws.amazon.com/bedrock/latest/userguide/models-features.html) \n",
    "    \n",
    "- [Model support by AWS Region in Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html)\n",
    "\n",
    "<div style=\"background-color: #f0f7fb; padding: 15px; border-left: 6px solid #2196F3; margin-bottom: 15px;\">\n",
    "<span style=\"color: #2196F3;\">ⓘ Note</span><br>\n",
    "Some models are accessible in some Regions only through cross-region inference. To learn more about cross-region inference, see \n",
    "    <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html\">Increase throughput with cross-region-inference<a> and <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html\">Supported Regions and models for inference profiles</a>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995d223-44b1-4c3c-88bc-1fd2a2c93f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this to the model id for your preferred Foundation Model for Amazon Bedrock Agent\n",
    "foundation_model_id = 'us.anthropic.claude-3-5-haiku-20241022-v1:0' \n",
    "\n",
    "stack_resource_attributes = helper_functions.get_stack_outputs()\n",
    "agent_service_role_arn = stack_resource_attributes['AgentServiceRole']\n",
    "agent_actions_lambda_arn = stack_resource_attributes['ClaimsReviewAgentActionLambdaFunction']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e227ebb-bd66-4e98-a3f4-c9a5df0e1a63",
   "metadata": {},
   "source": [
    "### Setup Agent Instruction\n",
    "We have a predesigned agent instruction that we will use for our claims processing agent. The instruction  describe what the agent is designed to do. We use base prompt templates for the Bedrock Agent for the purpose of this guidance solution. \n",
    "\n",
    "You can enhance your agent's accuracy through modifying these prompt templates to provide detailed configurations. See [Enhance agent's accuracy using advanced prompt templates in Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/advanced-prompts.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab82f36-c518-4258-bbe9-1de93900e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/agent_resources/agent_prompt.txt','r') as f:\n",
    "    agent_instruction = f.read()\n",
    "helper_functions.show_popup_link('View Agent Instruction', agent_instruction, \"agent_instruction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5565c08-e3c7-4a9b-9b6e-b6840879de70",
   "metadata": {},
   "source": [
    "### Create Agent\n",
    "With the Agent Instruction setup and foundation model chosen, we can now create our agent that can help with insurance claims processing. Subsequently we would define an action group and setup a Knowledge Base for the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134767e-f3e5-418d-91d1-3da326c272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id, status, version, agent_arn = bedrock_utils.create_agent(bedrock_agent,\n",
    "    agentName=f'claims-agent-{account_id}',\n",
    "    agent_service_role_arn=agent_service_role_arn,\n",
    "    description='claims review agent',\n",
    "    foundation_model_id=foundation_model_id,\n",
    "    agent_instruction=agent_instruction,\n",
    "    orchestrationType='DEFAULT'\n",
    ")\n",
    "version = version or 'DRAFT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda86694-eac0-4a73-80f4-9921215fbddc",
   "metadata": {},
   "source": [
    "### Create Agent Action Group\n",
    "We use Action groups with our Bedrock agent to define the actions that the agent should perform. We setup an Open API Schema with descriptions, structure, and parameters that define each action in the action group as an API operation.\n",
    "\n",
    "The agent uses the schema to determine the API operation that it needs to invoke and the parameters that are required to make the API request. These details are then sent through to the pre-created Lambda function that has the business logic to carry out the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2491c-7202-48cf-b6aa-d8a25f7412c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/agent_resources/agent_action_schema.json') as f:\n",
    "    api_schema = f.read()\n",
    "helper_functions.show_popup_link('View OpenAPI Schema for Actions', api_schema, \"action_schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccdad9-35b6-4628-b5ec-a691c5716831",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_action_group_response = bedrock_utils.create_agent_action_group(bedrock_agent,\n",
    "    actionGroupName='claims-review-actions',\n",
    "    description='claims review agent actions',\n",
    "    actionGroupState='ENABLED',\n",
    "    agentId=agent_id,\n",
    "    agentVersion=version,\n",
    "    apiSchema={\n",
    "        'payload': api_schema,\n",
    "    },\n",
    "    agent_actions_lambda_arn=agent_actions_lambda_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d000a7c-f718-4f71-a5ad-01d4a84e82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "agent_action_lambda_function_arn = stack_resource_attributes['ClaimsReviewAgentActionLambdaFunction']\n",
    "bedrock_utils.add_lambda_permission(\n",
    "    function_name=agent_action_lambda_function_arn.split(\":\")[-1],\n",
    "    principal='bedrock.amazonaws.com',\n",
    "    action='lambda:InvokeFunction',\n",
    "    source_arn=agent_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640cc51-dc0a-4a93-a59e-2eae2b7608d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "associate_agent_kb_response = bedrock_utils.associate_agent_knowledge_base(bedrock_agent,\n",
    "    agentId=agent_id,\n",
    "    agentVersion='DRAFT',\n",
    "    description='Claims Evidence of Coverage, used to verify if claims are covered under specific coverage plan terms',\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    knowledgeBaseState='ENABLED'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83f13d-2e8f-4756-9ddf-dcf9206bb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agent.prepare_agent(agentId=agent_id)\n",
    "status_response = helper_functions.wait_for_completion(\n",
    "                client=bedrock_agent,\n",
    "                get_status_function=bedrock_agent.get_agent,\n",
    "                status_kwargs={\n",
    "                    'agentId': agent_id\n",
    "                },\n",
    "                completion_states=['PREPARED'],\n",
    "                error_states=['FAILED'],\n",
    "                status_path_in_response='agent.agentStatus',\n",
    "                max_iterations=5,\n",
    "                delay=15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972b125-5c07-44c5-81c7-b728a69a650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_alias_id, status  = bedrock_utils.create_agent_alias(bedrock_agent,\n",
    "    agentAliasName='LIVE',\n",
    "    agentId=agent_id,\n",
    "    description='LIVE version of agent'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff09842-576a-4ef1-8c20-176c5b9fffbc",
   "metadata": {},
   "source": [
    "## Setting up Bedrock Data Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c56a2-74ef-4b25-88ba-841ccd05a4dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Sample Document\n",
    "\n",
    "For this lab, we use a sample `Medical Claim` pack. The pack contains the medical claims form (CMS 1500) as well as supporting documents including identify documents etc. For the purpose of this solution, we would be focussing on the CMS 1500 form to extract claims data using a custom blueprint with BDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f83d39-80fd-49e1-bbfb-652db85a29ad",
   "metadata": {},
   "source": [
    "### Download sample and store to S3 Input location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0dabd1-ec9b-4aac-a317-d93ede0e0465",
   "metadata": {},
   "source": [
    "Let's download the claims pack sample and store it in the S3 Location that we use for BDA input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04759fad-0ebd-4949-977b-d69940ecae0b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the document\n",
    "document_url = 'https://ws-assets-prod-iad-r-iad-ed304a55c2ca1aee.s3.us-east-1.amazonaws.com/c64e3606-ab68-4521-81ea-b2eb36c993b9/samples/sample1_cms-1500-P.pdf'\n",
    "local_documents_path = 'data/documents'\n",
    "\n",
    "# Create full path of directories\n",
    "os.makedirs(local_documents_path, exist_ok=True)\n",
    "local_file_name = 'sample1_cms-1500-P.pdf'\n",
    "local_file_path = os.path.join(local_documents_path, local_file_name)\n",
    "!curl {document_url} --output {local_file_path}\n",
    "\n",
    "document_s3_uri = f'{bda_s3_input_location}/{local_file_name}'\n",
    "target_s3_bucket, target_s3_key = helper_functions.get_bucket_and_key(document_s3_uri)\n",
    "s3_client.upload_file(local_file_path, target_s3_bucket, target_s3_key)\n",
    "\n",
    "print(f\"Downloaded file to: {local_file_path}\")\n",
    "print(f\"Uploaded file to S3: {target_s3_key}\")\n",
    "print(f\"document_s3_uri: {document_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb3f1f-40b1-485f-a8b1-0a6513d75faa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### View Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340ffd98-4fe6-472c-b492-3cce9cf8299a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IFrame(local_file_path, width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9119c80-f8d1-499a-bbec-e1a010ed1088",
   "metadata": {},
   "source": [
    "### Create Blueprint for Medical Claim form (CMS 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefce02-2295-49b3-b98b-a585073ed48f",
   "metadata": {},
   "source": [
    "Our sample file contains multiple document types, but we are only interested in the data in the Claims form. So we use a single custom blueprints to process the document. \n",
    "\n",
    "We use the create_blueprint operation (or update_blueprint to update an existing blueprint) in the boto3 API to create/update the blueprint. Each blueprint that you create is an AWS resource with its own blueprint ID and ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e38e36-2ecd-436e-912a-819555b6bdff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "blueprint = {\n",
    "    \"name\": 'claim-form',\n",
    "    \"description\": 'Blueprint for Medical Claim form CMS 1500',\n",
    "    \"type\": 'DOCUMENT',\n",
    "    \"stage\": 'LIVE',\n",
    "    \"schema_path\": 'data/blueprint/claims_form.json'\n",
    "}\n",
    "with open(blueprint['schema_path']) as f:\n",
    "    blueprint_schema = json.load(f)\n",
    "    blueprint_arn = helper_functions.create_or_update_blueprint(\n",
    "        bda_client, \n",
    "        blueprint['name'], \n",
    "        blueprint['description'], \n",
    "        blueprint['type'],\n",
    "        blueprint['stage'],\n",
    "        blueprint_schema\n",
    "    )\n",
    "print(f\"Created/Update Blueprint, blueprint_arn={blueprint_arn}\")\n",
    "blueprint = bda_client.get_blueprint(\n",
    "    blueprintArn=blueprint_arn,\n",
    "    blueprintStage='LIVE'\n",
    ")\n",
    "schema = json.loads(blueprint['blueprint']['schema'])\n",
    "helper_functions.show_popup_link('View Blueprint', json.dumps(schema, indent=2), \"blueprint_schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca730c-f52f-4d1f-8c15-d72648e16f6d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={\n",
    "        's3Uri': document_s3_uri\n",
    "    },\n",
    "    outputConfiguration={\n",
    "        's3Uri': bda_s3_output_location\n",
    "    },\n",
    "    dataAutomationProfileArn = f'arn:aws:bedrock:{region_name}:{account_id}:data-automation-profile/us.data-automation-v1',\n",
    "    blueprints=[\n",
    "        {\n",
    "            'blueprintArn': blueprint_arn\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "invocationArn = response['invocationArn']\n",
    "print(f'Invoked data automation job with invocation arn {invocationArn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00223e8f-62f0-4677-9e80-957c95c7c641",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "status_response = helper_functions.wait_for_completion(\n",
    "            client=bda_client,\n",
    "            get_status_function=bda_runtime_client.get_data_automation_status,\n",
    "            status_kwargs={'invocationArn': invocationArn},\n",
    "            completion_states=['Success'],\n",
    "            error_states=['ClientError', 'ServiceError'],\n",
    "            status_path_in_response='status',\n",
    "            max_iterations=15,\n",
    "            delay=30\n",
    ")\n",
    "if status_response['status'] == 'Success':\n",
    "    job_metadata_s3_location = status_response['outputConfiguration']['s3Uri']\n",
    "else:\n",
    "    raise Exception(f'Invocation Job Error, error_type={status_response[\"error_type\"]},error_message={status_response[\"error_message\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56523d4c-15d4-4084-af9f-ed6379571402",
   "metadata": {},
   "source": [
    "### Retrieve job metadata\n",
    "The results of the file processing are stored in the S3 bucket configured earlier. Let's retrieve and explore the job metadata response that BDA produces in the configured S3 output bucket.\n",
    "\n",
    "The job metadata contains the job details including job_id, the job_status and the identified modality for the job. It also contains the output information with an S3 location for the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a27e29-6b19-48f2-984d-5693dfec7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_metadata = json.loads(helper_functions.read_s3_object(job_metadata_s3_location))\n",
    "job_id = job_metadata['job_id']\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "job_status = pd.DataFrame({\n",
    "    'job_id': [job_metadata['job_id']],\n",
    "    'job_status': [job_metadata['job_status']],\n",
    "    'semantic_modality': [job_metadata['semantic_modality']]\n",
    "}).T\n",
    "job_metadata_table = pd.DataFrame(job_metadata['output_metadata'][0]['segment_metadata']).fillna('').T\n",
    "job_metadata_table.index.name='Segment Index'\n",
    "job_metadata_json = JSON(job_metadata, root=\"job_metadata\", expanded=True)\n",
    "# Display the widget\n",
    "display_functions.display_multiple(\n",
    "    [display_functions.get_view(job_status), display_functions.get_view(job_metadata_table), display_functions.get_view(job_metadata_json)], \n",
    "    [\"Job Status\", \"Output Info\", \"Metadata (JSON)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355175d3-8c03-4a9c-b60c-3ae66c34a9f5",
   "metadata": {},
   "source": [
    "### View Segments and Matched Blueprints\n",
    "As we can see in the job metadata, BDA creates a segment section each for each individual document that it has identified in the file. Each segment section has details on the matched blueprint and the results of the extraction. For each segment, BDA also outputs the page indices (one or more) from the original file.\n",
    "\n",
    "We can now get the custom output corresponding to each segment and look at the insights that BDA custom output produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f8896-0bdf-441c-87e3-56b40d4ad6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_id = 0\n",
    "segments_metadata = next(item[\"segment_metadata\"]\n",
    "                                for item in job_metadata[\"output_metadata\"] \n",
    "                                if item['asset_id'] == asset_id)\n",
    "\n",
    "custom_outputs = [json.loads(helper_functions.read_s3_object(segment_metadata.get('custom_output_path'))) if segment_metadata.get('custom_output_status') == 'MATCH' else None for segment_metadata in segments_metadata]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425c7b0-2b78-4884-9e33-dbdb48d8603d",
   "metadata": {},
   "source": [
    "### View Custom output summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2125c4-f9c3-4bf5-9af6-b300a954ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_outputs_json = JSON(custom_outputs, root=\"custom_outputs\", expanded=False)\n",
    "custom_outputs_table = pd.DataFrame(helper_functions.get_summaries(custom_outputs)).fillna('')\n",
    "\n",
    "display_functions.display_multiple(\n",
    "    [\n",
    "        display_functions.get_view(custom_outputs_table.style.hide(axis='index')),\n",
    "        display_functions.get_view(custom_outputs_json)\n",
    "    ], \n",
    "    [\"Table View\", \"Raw JSON\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba896c43-fbcd-46cd-b82c-48f61b39c42e",
   "metadata": {},
   "source": [
    "### Extract Inference Results and Store in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef2259-c13d-4684-8926-0be9f6fe5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_result = custom_outputs[0]['inference_result']\n",
    "JSON(inference_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e0bf4-5e40-44d8-a268-fdeccef93b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_input_bucket, agent_input_key = helper_functions.get_bucket_and_key(agent_review_s3_input_location)\n",
    "s3_client.put_object(\n",
    "    Bucket=agent_input_bucket,\n",
    "    Key=f'{agent_input_key}/{job_id}.json',\n",
    "    Body=json.dumps(inference_result)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8314ad6e-c298-4012-8643-d1722888839c",
   "metadata": {},
   "source": [
    "### Invoke Agent for Claim Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0cc00-3205-4b86-9366-3c5eb9d1eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputText=f\"Review the claim using claim form data in S3 URI {agent_review_s3_input_location}/{job_id}.json\"\n",
    "agent_answer = bedrock_utils.invoke_agent_helper(bedrock_agent_runtime_client=bedrock_agent_runtime, \n",
    "                    query=inputText, session_id=str(uuid.uuid4()),\n",
    "                    agent_id=agent_id, alias_id=agent_alias_id,enable_trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82e49c-662e-4ccc-a348-179d6f179db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(agent_answer.replace('$', r'\\$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00614e-0815-48ae-bcb7-2e8469333c33",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0fc3a-832d-4b19-b3d1-4f5e790c0816",
   "metadata": {},
   "source": [
    "Let's delete the local copies of downloaded sample files and the file we uploaded to s3 input directory, as well as the generated job output files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f0ad6-b145-455c-bf8b-6da84997963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete S3 File\n",
    "s3_client.delete_object(Bucket=target_s3_bucket, Key=target_s3_key)\n",
    "\n",
    "# Delete local file\n",
    "if os.path.exists(local_documents_path):\n",
    "    shutil.rmtree(local_documents_path)\n",
    "\n",
    "# Delete bda workshop location that we created our contents under in S3\n",
    "#!aws s3 rm {bda_workshop_s3_location} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eacd11-7659-46c5-84a2-bf637b05bf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
